<!doctype html><html lang=ja dir=auto>
<head><meta charset=utf-8>
<meta http-equiv=x-ua-compatible content="IE=edge">
<meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no">
<meta name=robots content="index, follow">
<title>研究 | Sekken</title>
<meta name=keywords content>
<meta name=description content="原著論文  Kentaro Seki, Shinnosuke Takamichi, Takaaki Saeki and Hiroshi Saruwatari, &ldquo;TTSOps: A Closed-Loop Corpus Optimization Framework for Training Multi-Speaker TTS Models from Dark Data&rdquo;, IEEE Transactions on Audio, Speech, and Language Processing. (ACCEPTED) [arXiv preprint] Kentaro Seki, Nobutaka Ito, Kazuki Yamauchi, Yuki Okamoto, Kouei Yamaoka, Yuki Saito, Shinnosuke Takamichi, Hiroshi Saruwatari, &ldquo;Language-queried target speech extraction using para-linguistic and non-linguistic prompts,&rdquo; Acoustical Science and Technology, Vol. 46, No. 6, pp. 1&ndash;5, Nov.">
<meta name=author content="trgkpc">
<link rel=canonical href=http://trgkpc.github.io/fixed/research/>
<meta name=google-site-verification content="XYZabc">
<meta name=yandex-verification content="XYZabc">
<meta name=msvalidate.01 content="XYZabc">
<link crossorigin=anonymous href=/assets/css/stylesheet.bccfefac377bc340f06c260aed1bddf49a4354816d7c570d6aac75a997986c95.css integrity="sha256-vM/vrDd7w0DwbCYK7Rvd9JpDVIFtfFcNaqx1qZeYbJU=" rel="preload stylesheet" as=style>
<script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=http://trgkpc.github.io/%3Clink%20/%20abs%20url%3E>
<link rel=icon type=image/png sizes=16x16 href=http://trgkpc.github.io/%3Clink%20/%20abs%20url%3E>
<link rel=icon type=image/png sizes=32x32 href=http://trgkpc.github.io/%3Clink%20/%20abs%20url%3E>
<link rel=apple-touch-icon href=http://trgkpc.github.io/%3Clink%20/%20abs%20url%3E>
<link rel=mask-icon href=http://trgkpc.github.io/%3Clink%20/%20abs%20url%3E>
<meta name=theme-color content="#2e2e33">
<meta name=msapplication-TileColor content="#2e2e33">
<link rel=alternate hreflang=ja href=http://trgkpc.github.io/fixed/research/>
<link rel=alternate hreflang=en href=http://trgkpc.github.io/en/fixed/research/>
<noscript>
<style>#theme-toggle,.top-link{display:none}</style>
<style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style>
</noscript>
<script type=application/javascript>var doNotTrack=!1;doNotTrack||(function(a,e,f,g,b,c,d){a.GoogleAnalyticsObject=b,a[b]=a[b]||function(){(a[b].q=a[b].q||[]).push(arguments)},a[b].l=1*new Date,c=e.createElement(f),d=e.getElementsByTagName(f)[0],c.async=1,c.src=g,d.parentNode.insertBefore(c,d)}(window,document,'script','https://www.google-analytics.com/analytics.js','ga'),ga('create','UA-123-45','auto'),ga('send','pageview'))</script><meta property="og:title" content="研究">
<meta property="og:description" content="原著論文  Kentaro Seki, Shinnosuke Takamichi, Takaaki Saeki and Hiroshi Saruwatari, &ldquo;TTSOps: A Closed-Loop Corpus Optimization Framework for Training Multi-Speaker TTS Models from Dark Data&rdquo;, IEEE Transactions on Audio, Speech, and Language Processing. (ACCEPTED) [arXiv preprint] Kentaro Seki, Nobutaka Ito, Kazuki Yamauchi, Yuki Okamoto, Kouei Yamaoka, Yuki Saito, Shinnosuke Takamichi, Hiroshi Saruwatari, &ldquo;Language-queried target speech extraction using para-linguistic and non-linguistic prompts,&rdquo; Acoustical Science and Technology, Vol. 46, No. 6, pp. 1&ndash;5, Nov.">
<meta property="og:type" content="article">
<meta property="og:url" content="http://trgkpc.github.io/fixed/research/"><meta property="og:image" content="http://trgkpc.github.io/img/profile.jpg"><meta property="article:section" content="fixed">
<meta property="article:published_time" content="2023-02-11T01:46:06+09:00">
<meta property="article:modified_time" content="2023-02-11T01:46:06+09:00"><meta property="og:site_name" content="Sekken">
<meta name=twitter:card content="summary_large_image">
<meta name=twitter:image content="http://trgkpc.github.io/img/profile.jpg">
<meta name=twitter:title content="研究">
<meta name=twitter:description content="原著論文  Kentaro Seki, Shinnosuke Takamichi, Takaaki Saeki and Hiroshi Saruwatari, &ldquo;TTSOps: A Closed-Loop Corpus Optimization Framework for Training Multi-Speaker TTS Models from Dark Data&rdquo;, IEEE Transactions on Audio, Speech, and Language Processing. (ACCEPTED) [arXiv preprint] Kentaro Seki, Nobutaka Ito, Kazuki Yamauchi, Yuki Okamoto, Kouei Yamaoka, Yuki Saito, Shinnosuke Takamichi, Hiroshi Saruwatari, &ldquo;Language-queried target speech extraction using para-linguistic and non-linguistic prompts,&rdquo; Acoustical Science and Technology, Vol. 46, No. 6, pp. 1&ndash;5, Nov.">
<script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Fixeds","item":"http://trgkpc.github.io/fixed/"},{"@type":"ListItem","position":2,"name":"研究","item":"http://trgkpc.github.io/fixed/research/"}]}</script>
<script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"研究","name":"研究","description":"原著論文  Kentaro Seki, Shinnosuke Takamichi, Takaaki Saeki and Hiroshi Saruwatari, \u0026ldquo;TTSOps: A Closed-Loop Corpus Optimization Framework for Training Multi-Speaker TTS Models from Dark Data\u0026rdquo;, IEEE Transactions on Audio, Speech, and Language Processing. (ACCEPTED) [arXiv preprint] Kentaro Seki, Nobutaka Ito, Kazuki Yamauchi, Yuki Okamoto, Kouei Yamaoka, Yuki Saito, Shinnosuke Takamichi, Hiroshi Saruwatari, \u0026ldquo;Language-queried target speech extraction using para-linguistic and non-linguistic prompts,\u0026rdquo; Acoustical Science and Technology, Vol. 46, No. 6, pp. 1\u0026ndash;5, Nov.","keywords":[],"articleBody":"原著論文  Kentaro Seki, Shinnosuke Takamichi, Takaaki Saeki and Hiroshi Saruwatari, “TTSOps: A Closed-Loop Corpus Optimization Framework for Training Multi-Speaker TTS Models from Dark Data”, IEEE Transactions on Audio, Speech, and Language Processing. (ACCEPTED) [arXiv preprint] Kentaro Seki, Nobutaka Ito, Kazuki Yamauchi, Yuki Okamoto, Kouei Yamaoka, Yuki Saito, Shinnosuke Takamichi, Hiroshi Saruwatari, “Language-queried target speech extraction using para-linguistic and non-linguistic prompts,” Acoustical Science and Technology, Vol. 46, No. 6, pp. 1–5, Nov. 2025.[OPEN ACCESS]  国際学会  Kentaro Seki, Shinnosuke Takamichi, Takaaki Saeki and Hiroshi Saruwatari, “Active Learning for Text-to-Speech Synthesis with Informative Sample Collection” in Proc. APSIPA ASC, 2025. [arXiv preprint] Kentaro Seki, Shinnosuke Takamichi, Norihiro Takamune, Yuki Saito, Kanami Imamura, and Hiroshi Saruwatari, “Spatial Voice Conversion: Voice Conversion Preserving Spatial Information and Non-target Signals” in Proc. Interspeech, 2024. Takuto Igarashi, Yuki Saito, Kentaro Seki, Shinnosuke Takamichi, Ryuichi Yamamoto, and Kentaro Tachibana and Hiroshi Saruwatari, “Noise-Robust Voice Conversion by Conditional Denoising Training Using Latent Variables of Recording Quality and Environment” in Proc. Interspeech, 2024. Yuki Saito, Takuto Igarashi, Kentaro Seki, Shinnosuke Takamichi, Ryuichi Yamamoto, Kentaro Tachibana, and Hiroshi Saruwatari. “SRC4VC: Smartphone-Recorded Corpus for Voice Conversion Benchmark” in Proc. Interspeech, 2024. Osamu Take, Shinnosuke Takamichi, Kentaro Seki, Yoshiaki Bando, and Hiroshi Saruwatari, “SaSLaW: Dialogue Speech Corpus with Audio-visual Egocentric Information Toward Environment-adaptive Dialogue Speech Synthesis” in Proc. Interspeech, 2024. Kentaro Seki, Shinnosuke Takamichi, Takaaki Saeki and Hiroshi Saruwatari, “Diversity-based core-set selection for text-to-speech with linguistic and acoustic features” in Proc. ICASSP, 2024.[arXiv preprint] Joonyong Park, Shinnosuke Takamichi, Tomohiko Nakamura, Kentaro Seki, Detai Xin and Hiroshi Saruwatari, “How Generative Spoken Language Modeling Encodes Noisy Speech: Investigation from Phonetics to Syntactics” in Proc. Interspeech, 2023. [arXiv preprint] Kentaro Seki, Shinnosuke Takamichi, Takaaki Saeki and Hiroshi Saruwatari, “Text-to-speech synthesis from dark data with evaluation-in-the-loop data selection” in Proc. ICASSP, 2023.[arXiv preprint]  国内学会  関 健太郎, 高道 慎之介, 佐伯 高明, 猿渡 洋, “データ単位前処理自動選択による音声合成コーパスのデータクレンジング”, 日本音響学会第153回(2025年春季)研究発表会. 関 健太郎, 李 莉, 関 翔悟, 山岡 洸瑛, “分散マイクロフォンアレイを用いたスポットフォーミングにおける空間フィルタと時間周波数マスクの同時最適化”, 日本音響学会第153回(2025年春季)研究発表会. 淺井 航平, 齋藤 佑樹, 中田 亘, 関 健太郎, 猿渡 洋, “話者オーバーラップ音声からの特徴抽出に向けた自己教師あり学習モデルの検討”, 日本音響学会第153回(2025年春季)研究発表会. 濱田 誉輝, 齋藤 佑樹, 中田 亘, 山内 一輝, 関 健太郎, 岡本 悠希, 猿渡 洋, “ペルソナ説明文を利用した合成音声の話者性制御手法の検討”, 日本音響学会第153回(2025年春季)研究発表会. 武 伯寒, 高道 慎之介, 関 健太郎, 猿渡 洋, “音環境に適応する音声合成能力を搭載した音声対話システムの構築と実証実験に基づく検討”, 情報処理学会 第155回 音声言語情報処理研究発表会, 2025年3月. 高田 賢太, 関 健太郎, 齋藤 佑樹, 山岡 洸瑛, 石川 悠人, 猿渡 洋, “オンライン空間音声変換に向けたBSS・VC・リミックスの統合”, 音声研究会, 2025年3月. 関健太郎, 高道慎之介, 佐伯高明, 猿渡洋, “データ重要度評価に基づく能動学習を用いた音声合成”, 第27回情報論的学習理論ワークショップ, 2024年11月. 武 伯寒, 高道 慎之介, 関健太郎, 坂東 宜昭, 猿渡 洋, “音環境に適応するテキスト音声合成のための一人称視点コーパス構築”, 情報処理学会 第151回 音声言語情報処理研究発表会, 2024年3月. 五十嵐 琢斗, 齋藤 佑樹, 関健太郎, 高道慎之介, 山本 龍一, 橘 健太郎, 猿渡 洋, “音声品質と音響環境の潜在変数で条件付けた Denoising Trainingによるノイズロバスト音声変換”, 電子情報通信学会研究報告, 2024年3月. 齋藤 佑樹, 五十嵐 琢斗, 関健太郎, 高道慎之介, 山本 龍一, 橘 健太郎, 猿渡 洋, “SRC4VCデータセット：多話者音声変換モデルのベンチマークを目的とした実デバイス収録音声コーパス”, 電子情報通信学会研究報告, 2024年3月. 岡本 美柚, 関 健太郎, 高道 慎之介, 齋藤 佑樹, 伊藤 貴之, “ImTTS：印象推定の可視化を用いた多話者音声合成システム”, 情報処理学会 第201回 ヒューマンコンピュータインタラクション研究会, 2024年1月. 岡本 美柚, 関健太郎, 高道 慎之介, 齋藤 佑樹, 伊藤 貴之, “ImTTS：印象推定の可視化を用いた多話者音声合成システム”, NICOGRAPH 2023, 2023年12月（査読あり）. 関健太郎, 高道慎之介, 佐伯高明, 猿渡洋, “テキスト音声合成におけるデータサブセット選択のための指標検討”, 日本音響学会第150回(2023年秋季)研究発表会. 朴浚溶, 高道慎之介, 中村 友彦, 関健太郎, 辛德泰, 猿渡洋, “Generative Spoken Language Model を用いた劣化雑音音声の分析と他言語への適用”, 日本音響学会第149回(2023年春季)研究発表会. 関健太郎, 高道慎之介, 佐伯高明, 猿渡洋, “学習・評価ループを用いたデータ選択によるダークデータからの音声合成”, 日本音響学会第149回(2023年春季)研究発表会.[論文][スライド]  招待講演  Kentaro Seki, “Data Selection for Text-to-speech with Feedback from Automatic Evaluation of Naturalness on Synthetic Speech”, in Joint Workshop of VoicePersonae and ASVspoof (VoiceMOS mini workshop) 2023, Nov. 2023.  プレプリント  Wataru Nakata, Kentaro Seki, Hitomi Yanaka, Yuki Saito, Shinnosuke Takamichi, Hiroshi Saruwatari, “J-CHAT: Japanese Large-scale Spoken Dialogue Corpus for Spoken Dialogue Language Modeling”, 2024. [arXiv preprint]  予算  関 健太郎, “インターネットデータの活用によるテキスト音声合成の感情表現力向上”,2024 年度 特別研究員 DC1, 日本学術振興会. 中田 亘, 関 健太郎, “音声対話システムにおける表現力豊かな音声合成のためのデータセット整備と大規模言語モデルの言語知識の活用”, 300 万円, 2023 年度ディープテック人材育成事業「覚醒」, 産業技術総合研究所.  その他  関健太郎, “国際会議報告 INTERSPEECH”, 人工知能学会 第15回対話システムシンポジウム, 2024年11月.  受賞          2024.03 Google Travel Grants for Students in East Asia 受賞   2023.09 日本音響学会学生優秀発表賞受賞   2023.03 IEEE SPS Travel Grant for IEEE ICASSP 2023 受賞    ","wordCount":"583","inLanguage":"ja","datePublished":"2023-02-11T01:46:06+09:00","dateModified":"2023-02-11T01:46:06+09:00","author":[{"@type":"Person","name":"trgkpc"}],"mainEntityOfPage":{"@type":"WebPage","@id":"http://trgkpc.github.io/fixed/research/"},"publisher":{"@type":"Organization","name":"Sekken","logo":{"@type":"ImageObject","url":"http://trgkpc.github.io/%3Clink%20/%20abs%20url%3E"}}}</script>
</head>
<body id=top>
<script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add('dark'):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove('dark'):window.matchMedia('(prefers-color-scheme: dark)').matches&&document.body.classList.add('dark')</script>
<header class=header>
<nav class=nav>
<div class=logo>
<a href=http://trgkpc.github.io/ accesskey=h title="Home (Alt + H)">
<img src=http://trgkpc.github.io/apple-touch-icon.png alt aria-label=logo height=35>Home</a>
<div class=logo-switches>
<button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg>
</button>
<ul class=lang-switch><li>|</li>
<li>
<a href=http://trgkpc.github.io/en/ title=English aria-label=English>En</a>
</li>
</ul>
</div>
</div>
<ul id=menu>
<li>
<a href=http://trgkpc.github.io/posts title=投稿>
<span>投稿</span>
</a>
</li>
<li>
<a href=http://trgkpc.github.io/fixed/profile title=プロフィール>
<span>プロフィール</span>
</a>
</li>
<li>
<a href=http://trgkpc.github.io/fixed/research title=研究>
<span class=active>研究</span>
</a>
</li>
<li>
<a href=http://trgkpc.github.io/fixed/hobby title=趣味>
<span>趣味</span>
</a>
</li>
</ul>
</nav>
</header>
<main class=main>
<article class=post-single>
<header class=post-header>
<div class=breadcrumbs><a href=http://trgkpc.github.io/>ホーム</a>&nbsp;»&nbsp;<a href=http://trgkpc.github.io/fixed/>Fixeds</a></div>
<h1 class=post-title>
研究
</h1>
<div class=post-meta><span title="2023-02-11 01:46:06 +0900 +0900">2月 11, 2023</span>&nbsp;·&nbsp;3 分&nbsp;·&nbsp;583 文字&nbsp;·&nbsp;trgkpc&nbsp;|&nbsp;言語:
<ul class=i18n_list>
<li>
<a href=http://trgkpc.github.io/en/fixed/research/>En</a>
</li>
</ul>&nbsp;|&nbsp;<a href=https://github.com/trgkpc/trgkpc.github.io/blob/main/content/fixed/research.ja.md rel="noopener noreferrer" target=_blank>Suggest Changes</a>
</div>
</header>
<div class=post-content><h2 id=原著論文>原著論文<a hidden class=anchor aria-hidden=true href=#原著論文>#</a></h2>
<ol>
<li><strong>Kentaro Seki</strong>, Shinnosuke Takamichi, Takaaki Saeki and Hiroshi Saruwatari, &ldquo;TTSOps: A Closed-Loop Corpus Optimization Framework for Training Multi-Speaker TTS Models from Dark Data&rdquo;, IEEE Transactions on Audio, Speech, and Language Processing. (ACCEPTED) [<a href=https://arxiv.org/abs/2506.15614>arXiv preprint</a>]</li>
<li><strong>Kentaro Seki</strong>, Nobutaka Ito, Kazuki Yamauchi, Yuki Okamoto, Kouei Yamaoka, Yuki Saito, Shinnosuke Takamichi, Hiroshi Saruwatari, &ldquo;Language-queried target speech extraction using para-linguistic and non-linguistic prompts,&rdquo; Acoustical Science and Technology, Vol. 46, No. 6, pp. 1&ndash;5, Nov. 2025.[<a href=https://www.jstage.jst.go.jp/article/ast/46/6/46_e25.27/_article>OPEN ACCESS</a>]</li>
</ol>
<h2 id=国際学会>国際学会<a hidden class=anchor aria-hidden=true href=#国際学会>#</a></h2>
<ol>
<li><strong>Kentaro Seki</strong>, Shinnosuke Takamichi, Takaaki Saeki and Hiroshi Saruwatari, &ldquo;Active Learning for Text-to-Speech Synthesis with Informative Sample Collection&rdquo; in Proc. APSIPA ASC, 2025. [<a href=https://arxiv.org/abs/2507.08319>arXiv preprint</a>]</li>
<li><strong>Kentaro Seki</strong>, Shinnosuke Takamichi, Norihiro Takamune, Yuki Saito, Kanami Imamura, and Hiroshi Saruwatari, &ldquo;Spatial Voice Conversion: Voice Conversion Preserving Spatial Information and Non-target Signals&rdquo; in Proc. Interspeech, 2024.</li>
<li>Takuto Igarashi, Yuki Saito, <strong>Kentaro Seki</strong>, Shinnosuke Takamichi, Ryuichi Yamamoto, and Kentaro Tachibana and Hiroshi Saruwatari, &ldquo;Noise-Robust Voice Conversion by Conditional Denoising Training Using Latent Variables of Recording Quality and Environment&rdquo; in Proc. Interspeech, 2024.</li>
<li>Yuki Saito, Takuto Igarashi, <strong>Kentaro Seki</strong>, Shinnosuke Takamichi, Ryuichi Yamamoto, Kentaro Tachibana, and Hiroshi Saruwatari. &ldquo;SRC4VC: Smartphone-Recorded Corpus for Voice Conversion Benchmark&rdquo; in Proc. Interspeech, 2024.</li>
<li>Osamu Take, Shinnosuke Takamichi, <strong>Kentaro Seki</strong>, Yoshiaki Bando, and Hiroshi Saruwatari, &ldquo;SaSLaW: Dialogue Speech Corpus with Audio-visual Egocentric Information Toward Environment-adaptive Dialogue Speech Synthesis&rdquo; in Proc. Interspeech, 2024.</li>
<li><strong>Kentaro Seki</strong>, Shinnosuke Takamichi, Takaaki Saeki and Hiroshi Saruwatari, &ldquo;Diversity-based core-set selection for text-to-speech with linguistic and acoustic features&rdquo; in Proc. ICASSP, 2024.[<a href=https://arxiv.org/abs/2309.08127>arXiv preprint</a>]</li>
<li>Joonyong Park, Shinnosuke Takamichi, Tomohiko Nakamura, <strong>Kentaro Seki</strong>, Detai Xin and Hiroshi Saruwatari, &ldquo;How Generative Spoken Language Modeling Encodes Noisy Speech: Investigation from Phonetics to Syntactics&rdquo; in Proc. Interspeech, 2023. [<a href=https://arxiv.org/abs/2306.00697>arXiv preprint</a>]</li>
<li><strong>Kentaro Seki</strong>, Shinnosuke Takamichi, Takaaki Saeki and Hiroshi Saruwatari, &ldquo;Text-to-speech synthesis from dark data with evaluation-in-the-loop data selection&rdquo; in Proc. ICASSP, 2023.[<a href=https://arxiv.org/abs/2210.14850>arXiv preprint</a>]</li>
</ol>
<h2 id=国内学会>国内学会<a hidden class=anchor aria-hidden=true href=#国内学会>#</a></h2>
<ol>
<li>関 健太郎, 高道 慎之介, 佐伯 高明, 猿渡 洋, &ldquo;データ単位前処理自動選択による音声合成コーパスのデータクレンジング&rdquo;, 日本音響学会第153回(2025年春季)研究発表会.</li>
<li>関 健太郎, 李 莉, 関 翔悟, 山岡 洸瑛, &ldquo;分散マイクロフォンアレイを用いたスポットフォーミングにおける空間フィルタと時間周波数マスクの同時最適化&rdquo;, 日本音響学会第153回(2025年春季)研究発表会.</li>
<li>淺井 航平, 齋藤 佑樹, 中田 亘, 関 健太郎, 猿渡 洋, &ldquo;話者オーバーラップ音声からの特徴抽出に向けた自己教師あり学習モデルの検討&rdquo;, 日本音響学会第153回(2025年春季)研究発表会.</li>
<li>濱田 誉輝, 齋藤 佑樹, 中田 亘, 山内 一輝, 関 健太郎, 岡本 悠希, 猿渡 洋, &ldquo;ペルソナ説明文を利用した合成音声の話者性制御手法の検討&rdquo;, 日本音響学会第153回(2025年春季)研究発表会.</li>
<li>武 伯寒, 高道 慎之介, 関 健太郎, 猿渡 洋, &ldquo;音環境に適応する音声合成能力を搭載した音声対話システムの構築と実証実験に基づく検討&rdquo;, 情報処理学会 第155回 音声言語情報処理研究発表会, 2025年3月.</li>
<li>高田 賢太, <strong>関 健太郎</strong>, 齋藤 佑樹, 山岡 洸瑛, 石川 悠人, 猿渡 洋, &ldquo;オンライン空間音声変換に向けたBSS・VC・リミックスの統合&rdquo;, 音声研究会, 2025年3月.</li>
<li><strong>関健太郎</strong>, 高道慎之介, 佐伯高明, 猿渡洋, &ldquo;データ重要度評価に基づく能動学習を用いた音声合成&rdquo;, 第27回情報論的学習理論ワークショップ, 2024年11月.</li>
<li>武 伯寒, 高道 慎之介, <strong>関健太郎</strong>, 坂東 宜昭, 猿渡 洋, &ldquo;音環境に適応するテキスト音声合成のための一人称視点コーパス構築&rdquo;, 情報処理学会 第151回 音声言語情報処理研究発表会, 2024年3月.</li>
<li>五十嵐 琢斗, 齋藤 佑樹, <strong>関健太郎</strong>, 高道慎之介, 山本 龍一, 橘 健太郎, 猿渡 洋, &ldquo;音声品質と音響環境の潜在変数で条件付けた Denoising Trainingによるノイズロバスト音声変換&rdquo;, 電子情報通信学会研究報告, 2024年3月.</li>
<li>齋藤 佑樹, 五十嵐 琢斗, <strong>関健太郎</strong>, 高道慎之介, 山本 龍一, 橘 健太郎, 猿渡 洋, &ldquo;SRC4VCデータセット：多話者音声変換モデルのベンチマークを目的とした実デバイス収録音声コーパス&rdquo;, 電子情報通信学会研究報告, 2024年3月.</li>
<li>岡本 美柚, <strong>関 健太郎</strong>, 高道 慎之介, 齋藤 佑樹, 伊藤 貴之, &ldquo;ImTTS：印象推定の可視化を用いた多話者音声合成システム&rdquo;, 情報処理学会 第201回 ヒューマンコンピュータインタラクション研究会, 2024年1月.</li>
<li>岡本 美柚, <strong>関健太郎</strong>, 高道 慎之介, 齋藤 佑樹, 伊藤 貴之, &ldquo;ImTTS：印象推定の可視化を用いた多話者音声合成システム&rdquo;, NICOGRAPH 2023, 2023年12月（査読あり）.</li>
<li><strong>関健太郎</strong>, 高道慎之介, 佐伯高明, 猿渡洋, &ldquo;テキスト音声合成におけるデータサブセット選択のための指標検討&rdquo;, 日本音響学会第150回(2023年秋季)研究発表会.</li>
<li>朴浚溶, 高道慎之介, 中村 友彦, <strong>関健太郎</strong>, 辛德泰, 猿渡洋, &ldquo;Generative Spoken Language Model を用いた劣化雑音音声の分析と他言語への適用&rdquo;, 日本音響学会第149回(2023年春季)研究発表会.</li>
<li><strong>関健太郎</strong>, 高道慎之介, 佐伯高明, 猿渡洋, &ldquo;学習・評価ループを用いたデータ選択によるダークデータからの音声合成&rdquo;, 日本音響学会第149回(2023年春季)研究発表会.[<a href="https://drive.google.com/file/d/1CjhVSW1ud5yviFVaV4hwQQxzAqdOKm0B/view?usp=share_link">論文</a>][<a href="https://drive.google.com/file/d/1-pYXJ__X9y0yIdZr8eY06vL7KIFpb0LJ/view?usp=share_link">スライド</a>]</li>
</ol>
<h2 id=招待講演>招待講演<a hidden class=anchor aria-hidden=true href=#招待講演>#</a></h2>
<ol>
<li><strong>Kentaro Seki</strong>, &ldquo;Data Selection for Text-to-speech with Feedback from Automatic Evaluation of Naturalness on Synthetic Speech&rdquo;, in Joint Workshop of VoicePersonae and ASVspoof (VoiceMOS mini workshop) 2023, Nov. 2023.</li>
</ol>
<h2 id=プレプリント>プレプリント<a hidden class=anchor aria-hidden=true href=#プレプリント>#</a></h2>
<ol>
<li>Wataru Nakata, <strong>Kentaro Seki</strong>, Hitomi Yanaka, Yuki Saito, Shinnosuke Takamichi, Hiroshi Saruwatari, &ldquo;J-CHAT: Japanese Large-scale Spoken Dialogue Corpus for Spoken Dialogue Language Modeling&rdquo;, 2024. [<a href=https://arxiv.org/abs/2407.15828>arXiv preprint</a>]</li>
</ol>
<h2 id=予算>予算<a hidden class=anchor aria-hidden=true href=#予算>#</a></h2>
<ol>
<li><strong>関 健太郎</strong>, <a href=https://kaken.nii.ac.jp/ja/grant/KAKENHI-PROJECT-24KJ0860/>“インターネットデータの活用によるテキスト音声合成の感情表現力向上”</a>,2024 年度 特別研究員 DC1, 日本学術振興会.</li>
<li>中田 亘, <strong>関 健太郎</strong>, &ldquo;音声対話システムにおける表現力豊かな音声合成のためのデータセット整備と大規模言語モデルの言語知識の活用&rdquo;, 300 万円, <a href=https://kakusei.aist.go.jp/>2023 年度ディープテック人材育成事業「覚醒」</a>, 産業技術総合研究所.</li>
</ol>
<h2 id=その他>その他<a hidden class=anchor aria-hidden=true href=#その他>#</a></h2>
<ol>
<li><strong>関健太郎</strong>, &ldquo;国際会議報告 INTERSPEECH&rdquo;, 人工知能学会 第15回対話システムシンポジウム, 2024年11月.</li>
</ol>
<h2 id=受賞>受賞<a hidden class=anchor aria-hidden=true href=#受賞>#</a></h2>
<table>
<thead>
<tr>
<th style=text-align:left></th>
<th style=text-align:left></th>
</tr>
</thead>
<tbody>
<tr>
<td style=text-align:left>2024.03</td>
<td style=text-align:left>Google Travel Grants for Students in East Asia 受賞</td>
</tr>
<tr>
<td style=text-align:left>2023.09</td>
<td style=text-align:left>日本音響学会学生優秀発表賞受賞</td>
</tr>
<tr>
<td style=text-align:left>2023.03</td>
<td style=text-align:left>IEEE SPS Travel Grant for IEEE ICASSP 2023 受賞</td>
</tr>
</tbody>
</table>
</div>
<footer class=post-footer>
<ul class=post-tags>
</ul>
<nav class=paginav>
<a class=prev href=http://trgkpc.github.io/fixed/hobby/>
<span class=title>« 前のページ</span>
<br>
<span>趣味</span>
</a>
<a class=next href=http://trgkpc.github.io/fixed/profile/>
<span class=title>次のページ »</span>
<br>
<span>プロフィール</span>
</a>
</nav>
<div class=share-buttons>
<a target=_blank rel="noopener noreferrer" aria-label="share 研究 on twitter" href="https://twitter.com/intent/tweet/?text=%e7%a0%94%e7%a9%b6&url=http%3a%2f%2ftrgkpc.github.io%2ffixed%2fresearch%2f&hashtags="><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM195.519 424.544c135.939.0 210.268-112.643 210.268-210.268.0-3.218.0-6.437-.153-9.502 14.406-10.421 26.973-23.448 36.935-38.314-13.18 5.824-27.433 9.809-42.452 11.648 15.326-9.196 26.973-23.602 32.49-40.92-14.252 8.429-30.038 14.56-46.896 17.931-13.487-14.406-32.644-23.295-53.946-23.295-40.767.0-73.87 33.104-73.87 73.87.0 5.824.613 11.494 1.992 16.858-61.456-3.065-115.862-32.49-152.337-77.241-6.284 10.881-9.962 23.601-9.962 37.088.0 25.594 13.027 48.276 32.95 61.456-12.107-.307-23.448-3.678-33.41-9.196v.92c0 35.862 25.441 65.594 59.311 72.49-6.13 1.686-12.72 2.606-19.464 2.606-4.751.0-9.348-.46-13.946-1.38 9.349 29.426 36.628 50.728 68.965 51.341-25.287 19.771-57.164 31.571-91.8 31.571-5.977.0-11.801-.306-17.625-1.073 32.337 21.15 71.264 33.41 112.95 33.41z"/></svg>
</a>
<a target=_blank rel="noopener noreferrer" aria-label="share 研究 on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&url=http%3a%2f%2ftrgkpc.github.io%2ffixed%2fresearch%2f&title=%e7%a0%94%e7%a9%b6&summary=%e7%a0%94%e7%a9%b6&source=http%3a%2f%2ftrgkpc.github.io%2ffixed%2fresearch%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg>
</a>
<a target=_blank rel="noopener noreferrer" aria-label="share 研究 on reddit" href="https://reddit.com/submit?url=http%3a%2f%2ftrgkpc.github.io%2ffixed%2fresearch%2f&title=%e7%a0%94%e7%a9%b6"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg>
</a>
<a target=_blank rel="noopener noreferrer" aria-label="share 研究 on facebook" href="https://facebook.com/sharer/sharer.php?u=http%3a%2f%2ftrgkpc.github.io%2ffixed%2fresearch%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg>
</a>
<a target=_blank rel="noopener noreferrer" aria-label="share 研究 on whatsapp" href="https://api.whatsapp.com/send?text=%e7%a0%94%e7%a9%b6%20-%20http%3a%2f%2ftrgkpc.github.io%2ffixed%2fresearch%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg>
</a>
<a target=_blank rel="noopener noreferrer" aria-label="share 研究 on telegram" href="https://telegram.me/share/url?text=%e7%a0%94%e7%a9%b6&url=http%3a%2f%2ftrgkpc.github.io%2ffixed%2fresearch%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg>
</a>
</div>
</footer>
</article>
</main>
<footer>
<script type=text/javascript src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</footer>
</body>
</html>